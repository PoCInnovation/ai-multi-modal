{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import GPT2Model, GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer_Fast:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "        self.model = GPT2Model.from_pretrained('gpt2')\n",
    "        self.tokens = None\n",
    "        self.tokens_ids = None\n",
    "        self.embeddings = None\n",
    "\n",
    "    def encode(self, text):\n",
    "        self.tokens = self.tokenizer.tokenize(text)\n",
    "        self.tokens_ids = self.tokenizer.convert_tokens_to_ids(self.tokens)\n",
    "\n",
    "        input_ids = torch.tensor(self.tokens_ids).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids)\n",
    "            self.embeddings = outputs.last_hidden_state\n",
    "        # print(self.embeddings)\n",
    "    \n",
    "    def decode(self, output_ids):\n",
    "        return self.tokenizer.decode(output_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT_2_small:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = Tokenizer_Fast()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer.model.to(self.device)\n",
    "\n",
    "    def forward(self, input_ids):  \n",
    "        None    \n",
    "    \n",
    "    def inference (self, text):\n",
    "        self.tokenizer.encode(text)\n",
    "        print(self.tokenizer.tokens)\n",
    "        print(self.tokenizer.tokens_ids)\n",
    "        print(self.tokenizer.embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT = GPT_2_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sal', 'ut', 'Ġcomment', 'Ġca', 'Ġva', 'Ġto', 'i', 'Ġ?']\n",
      "[21680, 315, 2912, 1275, 46935, 284, 72, 5633]\n",
      "tensor([[[-1.2295e-01, -5.4374e-02, -4.2545e-01,  ..., -1.2950e-02,\n",
      "          -2.2568e-02, -1.9512e-01],\n",
      "         [ 1.0597e-01, -8.2322e-01, -1.8428e-01,  ..., -8.9712e-03,\n",
      "          -4.1308e-03,  1.2744e-01],\n",
      "         [-1.7948e-01, -1.2089e-01, -1.5692e+00,  ..., -7.9745e-02,\n",
      "          -2.4997e-01,  2.2971e-01],\n",
      "         ...,\n",
      "         [ 2.6695e-01, -7.6107e-01, -2.8149e-01,  ...,  8.0095e-02,\n",
      "           5.3955e-04, -1.8076e-01],\n",
      "         [ 1.0001e-01, -7.3743e-01, -1.2922e+00,  ..., -3.7741e-01,\n",
      "          -9.4853e-02,  1.1161e-01],\n",
      "         [-2.8443e-02, -4.8196e-01, -1.3770e-01,  ...,  1.7493e-01,\n",
      "          -2.2351e-02, -1.1496e-01]]])\n"
     ]
    }
   ],
   "source": [
    "text = 'salut comment ca va toi ?'\n",
    "\n",
    "GPT.inference(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
